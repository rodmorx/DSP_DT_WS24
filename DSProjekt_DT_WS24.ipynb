{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodmorx/DSP_DT_WS24/blob/main/DSProjekt_DT_WS24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Sience Projekt WS24 - Dream Team"
      ],
      "metadata": {
        "id": "4OrEuUXasy-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install news-please"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVYHF-4ts2yC",
        "outputId": "89a20860-f396-43d6-c06e-79711fc0b11c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting news-please\n",
            "  Downloading news_please-1.6.13-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting Scrapy>=1.1.0 (from news-please)\n",
            "  Downloading Scrapy-2.11.2-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting PyMySQL>=0.7.9 (from news-please)\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting psycopg2-binary>=2.8.4 (from news-please)\n",
            "  Downloading psycopg2_binary-2.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting hjson>=1.5.8 (from news-please)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting elasticsearch>=2.4 (from news-please)\n",
            "  Downloading elasticsearch-8.15.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.3.2 in /usr/local/lib/python3.10/dist-packages (from news-please) (4.12.3)\n",
            "Collecting readability-lxml>=0.6.2 (from news-please)\n",
            "  Downloading readability_lxml-0.8.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langdetect>=1.0.7 (from news-please)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from news-please) (2.8.2)\n",
            "Collecting plac>=0.9.6 (from news-please)\n",
            "  Downloading plac-1.4.3-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting dotmap>=1.2.17 (from news-please)\n",
            "  Downloading dotmap-1.3.30-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting PyDispatcher>=2.0.5 (from news-please)\n",
            "  Downloading PyDispatcher-2.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting warcio>=1.3.3 (from news-please)\n",
            "  Downloading warcio-1.7.4-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Collecting ago>=0.0.9 (from news-please)\n",
            "  Downloading ago-0.0.95.tar.gz (4.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from news-please) (1.16.0)\n",
            "Requirement already satisfied: lxml>=3.3.5 in /usr/local/lib/python3.10/dist-packages (from news-please) (5.3.0)\n",
            "Collecting hurry.filesize>=0.9 (from news-please)\n",
            "  Downloading hurry.filesize-0.9.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bs4 (from news-please)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Collecting faust-cchardet>=2.1.18 (from news-please)\n",
            "  Downloading faust_cchardet-2.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Collecting boto3 (from news-please)\n",
            "  Downloading boto3-1.35.57-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting redis (from news-please)\n",
            "  Downloading redis-5.2.0-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting newspaper4k>=0.9.3.1 (from news-please)\n",
            "  Downloading newspaper4k-0.9.3.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting lxml-html-clean>=0.1.1 (from news-please)\n",
            "  Downloading lxml_html_clean-0.3.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from news-please) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.3.2->news-please) (2.6)\n",
            "Collecting elastic-transport<9,>=8.13 (from elasticsearch>=2.4->news-please)\n",
            "  Downloading elastic_transport-8.15.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from hurry.filesize>=0.9->news-please) (75.1.0)\n",
            "Requirement already satisfied: Pillow>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from newspaper4k>=0.9.3.1->news-please) (10.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from newspaper4k>=0.9.3.1->news-please) (6.0.2)\n",
            "Collecting feedparser>=6.0.0 (from newspaper4k>=0.9.3.1->news-please)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: nltk>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from newspaper4k>=0.9.3.1->news-please) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.10/dist-packages (from newspaper4k>=0.9.3.1->news-please) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from newspaper4k>=0.9.3.1->news-please) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from newspaper4k>=0.9.3.1->news-please) (2.32.3)\n",
            "Collecting tldextract>=2.0.1 (from newspaper4k>=0.9.3.1->news-please)\n",
            "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from readability-lxml>=0.6.2->news-please) (5.2.0)\n",
            "Collecting cssselect (from readability-lxml>=0.6.2->news-please)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting Twisted>=18.9.0 (from Scrapy>=1.1.0->news-please)\n",
            "  Downloading twisted-24.10.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from Scrapy>=1.1.0->news-please) (43.0.3)\n",
            "Collecting itemloaders>=1.0.1 (from Scrapy>=1.1.0->news-please)\n",
            "  Downloading itemloaders-1.3.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting parsel>=1.5.0 (from Scrapy>=1.1.0->news-please)\n",
            "  Downloading parsel-1.9.1-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyOpenSSL>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from Scrapy>=1.1.0->news-please) (24.2.1)\n",
            "Collecting queuelib>=1.4.2 (from Scrapy>=1.1.0->news-please)\n",
            "  Downloading queuelib-1.7.0-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting service-identity>=18.1.0 (from Scrapy>=1.1.0->news-please)\n",
            "  Downloading service_identity-24.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting w3lib>=1.17.0 (from Scrapy>=1.1.0->news-please)\n",
            "  Downloading w3lib-2.2.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting zope.interface>=5.1.0 (from Scrapy>=1.1.0->news-please)\n",
            "  Downloading zope.interface-7.1.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protego>=0.1.15 (from Scrapy>=1.1.0->news-please)\n",
            "  Downloading Protego-0.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting itemadapter>=0.1.0 (from Scrapy>=1.1.0->news-please)\n",
            "  Downloading itemadapter-0.9.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from Scrapy>=1.1.0->news-please) (24.1)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from Scrapy>=1.1.0->news-please) (0.7.1)\n",
            "Collecting botocore<1.36.0,>=1.35.57 (from boto3->news-please)\n",
            "  Downloading botocore-1.35.57-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->news-please)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->news-please)\n",
            "  Downloading s3transfer-0.10.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis->news-please) (4.0.3)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.57->boto3->news-please) (2.2.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->Scrapy>=1.1.0->news-please) (1.17.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch>=2.4->news-please) (2024.8.30)\n",
            "Collecting sgmllib3k (from feedparser>=6.0.0->newspaper4k>=0.9.3.1->news-please)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.6->newspaper4k>=0.9.3.1->news-please) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.6->newspaper4k>=0.9.3.1->news-please) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.6->newspaper4k>=0.9.3.1->news-please) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.6->newspaper4k>=0.9.3.1->news-please) (4.66.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->newspaper4k>=0.9.3.1->news-please) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->newspaper4k>=0.9.3.1->news-please) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->newspaper4k>=0.9.3.1->news-please) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->newspaper4k>=0.9.3.1->news-please) (3.10)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->Scrapy>=1.1.0->news-please) (24.2.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->Scrapy>=1.1.0->news-please) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->Scrapy>=1.1.0->news-please) (0.4.1)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper4k>=0.9.3.1->news-please)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper4k>=0.9.3.1->news-please) (3.16.1)\n",
            "Collecting automat>=24.8.0 (from Twisted>=18.9.0->Scrapy>=1.1.0->news-please)\n",
            "  Downloading Automat-24.8.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting constantly>=15.1 (from Twisted>=18.9.0->Scrapy>=1.1.0->news-please)\n",
            "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting hyperlink>=17.1.1 (from Twisted>=18.9.0->Scrapy>=1.1.0->news-please)\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting incremental>=24.7.0 (from Twisted>=18.9.0->Scrapy>=1.1.0->news-please)\n",
            "  Downloading incremental-24.7.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->Scrapy>=1.1.0->news-please) (2.22)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from incremental>=24.7.0->Twisted>=18.9.0->Scrapy>=1.1.0->news-please) (2.0.2)\n",
            "Downloading news_please-1.6.13-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.9/95.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dotmap-1.3.30-py3-none-any.whl (11 kB)\n",
            "Downloading elasticsearch-8.15.1-py3-none-any.whl (524 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.6/524.6 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faust_cchardet-2.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml_html_clean-0.3.1-py3-none-any.whl (13 kB)\n",
            "Downloading newspaper4k-0.9.3.1-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.6/296.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plac-1.4.3-py2.py3-none-any.whl (22 kB)\n",
            "Downloading psycopg2_binary-2.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
            "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading readability_lxml-0.8.1-py3-none-any.whl (20 kB)\n",
            "Downloading Scrapy-2.11.2-py2.py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading warcio-1.7.4-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.57-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Downloading redis-5.2.0-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.57-py3-none-any.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading elastic_transport-8.15.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading itemadapter-0.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading itemloaders-1.3.2-py3-none-any.whl (12 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading parsel-1.9.1-py2.py3-none-any.whl (17 kB)\n",
            "Downloading Protego-0.3.1-py2.py3-none-any.whl (8.5 kB)\n",
            "Downloading queuelib-1.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading s3transfer-0.10.3-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading service_identity-24.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading twisted-24.10.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading w3lib-2.2.1-py3-none-any.whl (21 kB)\n",
            "Downloading zope.interface-7.1.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.2/254.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Automat-24.8.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
            "Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading incremental-24.7.2-py3-none-any.whl (20 kB)\n",
            "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Building wheels for collected packages: ago, hurry.filesize, langdetect, sgmllib3k\n",
            "  Building wheel for ago (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ago: filename=ago-0.0.95-py3-none-any.whl size=5158 sha256=4be644390eaf7413b6d0e33bca37050d71b884b32ebefc58ca8c7bc44a4d49c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/b3/4b/1a778dcc4ab767ee37335851d6df8922cf08cc8c67e3daf8f8\n",
            "  Building wheel for hurry.filesize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hurry.filesize: filename=hurry.filesize-0.9-py3-none-any.whl size=4091 sha256=9adf80904c379e452da1b0e723f299708184616bc2012570c8c9d4e6172fad8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/af/17/1c4cd045d88f20d450522470819d85349c3388c151af64590b\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=8187b628a21bcf8fdc4d7e0166353539be9fd66c4182ce1b06107e532e5fe1e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=a9abcbb65521d482056c95db500437612fd120cdbc738aaa888154bf9b7b9182\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built ago hurry.filesize langdetect sgmllib3k\n",
            "Installing collected packages: sgmllib3k, PyDispatcher, plac, hjson, faust-cchardet, dotmap, ago, zope.interface, warcio, w3lib, redis, queuelib, PyMySQL, psycopg2-binary, protego, lxml-html-clean, langdetect, jmespath, itemadapter, incremental, hyperlink, hurry.filesize, feedparser, elastic-transport, cssselect, constantly, automat, Twisted, requests-file, readability-lxml, parsel, elasticsearch, bs4, botocore, tldextract, service-identity, s3transfer, itemloaders, Scrapy, newspaper4k, boto3, news-please\n",
            "Successfully installed PyDispatcher-2.0.7 PyMySQL-1.1.1 Scrapy-2.11.2 Twisted-24.10.0 ago-0.0.95 automat-24.8.1 boto3-1.35.57 botocore-1.35.57 bs4-0.0.2 constantly-23.10.4 cssselect-1.2.0 dotmap-1.3.30 elastic-transport-8.15.1 elasticsearch-8.15.1 faust-cchardet-2.1.19 feedparser-6.0.11 hjson-3.1.0 hurry.filesize-0.9 hyperlink-21.0.0 incremental-24.7.2 itemadapter-0.9.0 itemloaders-1.3.2 jmespath-1.0.1 langdetect-1.0.9 lxml-html-clean-0.3.1 news-please-1.6.13 newspaper4k-0.9.3.1 parsel-1.9.1 plac-1.4.3 protego-0.3.1 psycopg2-binary-2.9.10 queuelib-1.7.0 readability-lxml-0.8.1 redis-5.2.0 requests-file-2.1.0 s3transfer-0.10.3 service-identity-24.2.0 sgmllib3k-1.0.0 tldextract-5.1.3 w3lib-2.2.1 warcio-1.7.4 zope.interface-7.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from newsplease import NewsPlease\n",
        "import pandas as pd\n",
        "import urllib.parse\n",
        "## Can You READ THIS DREAM TEAM"
      ],
      "metadata": {
        "id": "Uz32WsCztVHp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract the domain (i.e., the newspaper/source) from the URL\n",
        "def extract_newspaper(url):\n",
        "    parsed_url = urllib.parse.urlparse(url)\n",
        "    domain = parsed_url.netloc\n",
        "    return domain.replace('www.', '')  # Clean up 'www.' if present"
      ],
      "metadata": {
        "id": "Ye1NHNkan2zS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to scrape an article from a URL and return relevant information\n",
        "def scrape_article(url):\n",
        "    try:\n",
        "        article = NewsPlease.from_url(url)\n",
        "        return {\n",
        "            'title': article.title,\n",
        "            'authors': article.authors,\n",
        "            'date_publish': article.date_publish,\n",
        "            'maintext': article.maintext,\n",
        "            'url': url,\n",
        "            'newspaper': extract_newspaper(url)  # Add newspaper information\n",
        "        }\n",
        "    except Exception as e:\n",
        "        # Return None if there's any error (e.g., 404, timeout)\n",
        "        print(f\"Error scraping {url}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "Q16b25Kx11c1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to scrape multicle articles and return a dataframe with relevant information\n",
        "def scrape_articles(url_list):\n",
        "    # Initialize an empty list to store scraped article data\n",
        "    articles_data = []\n",
        "\n",
        "    # Loop through each URL and scrape the article\n",
        "    for url in url_list:\n",
        "        article_data = scrape_article(url)\n",
        "        if article_data:\n",
        "            articles_data.append(article_data)\n",
        "\n",
        "    # Convert the list of dictionaries to a pandas DataFrame\n",
        "    df = pd.DataFrame(articles_data)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "xUC4EUKG2MXd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Usage\n",
        "urls = [\n",
        "    \"https://www.abendblatt.de/hamburg/hamburg-mitte/article407529183/elbtower-kauft-tuerkische-firma-hamburgs-kuenftiges-wahrzeichen.html\",\n",
        "    \"https://www.sueddeutsche.de/politik/israel-hisbollah-libanon-bank-gold-geld-krankenhaus-lux.TxxwzAtVsoRuvgqkHfMiuy\",\n",
        "    \"https://www.morgenpost.de/politik/article407533911/gruene-verbieten-hunde-wie-csu-zu-diesem-schwachsinn-kommt.html\"\n",
        "]\n",
        "\n",
        "# Scrape articles and create a DataFrame\n",
        "articles_df = scrape_articles(urls)\n",
        "\n",
        "# Display the dataframe\n",
        "print(articles_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NENtyFtq2RuH",
        "outputId": "bf4abb8f-9567-4fbb-c9ae-6439597238ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title            authors  \\\n",
            "0  Elbtower Hamburg: Drei Kaufinteressenten sind ...   [Ulrich Gaßdorf]   \n",
            "1   Israels Armee sucht den Goldschatz der Hisbollah    [Bernd Dörries]   \n",
            "2  Grüne verbieten Hunde? Wie CSU zu diesem „Schw...  [Daniel Weidmann]   \n",
            "\n",
            "         date_publish                                           maintext  \\\n",
            "0 2024-10-28 13:25:00  Hamburg. Zu den möglichen Investoren soll eine...   \n",
            "1 2024-10-22 14:56:01  Der Direktor des Krankenhauses, ein Parlaments...   \n",
            "2 2024-10-24 11:18:36  Berlin. Der CSU-Generalsekretär behauptet, die...   \n",
            "\n",
            "                                                 url        newspaper  \n",
            "0  https://www.abendblatt.de/hamburg/hamburg-mitt...    abendblatt.de  \n",
            "1  https://www.sueddeutsche.de/politik/israel-his...  sueddeutsche.de  \n",
            "2  https://www.morgenpost.de/politik/article40753...    morgenpost.de  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articles_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8qpOyQt8PIM",
        "outputId": "8f68233d-3c17-42ad-a73b-41928a9137aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count  Dtype         \n",
            "---  ------        --------------  -----         \n",
            " 0   title         3 non-null      object        \n",
            " 1   authors       3 non-null      object        \n",
            " 2   date_publish  3 non-null      datetime64[ns]\n",
            " 3   maintext      3 non-null      object        \n",
            " 4   url           3 non-null      object        \n",
            " 5   newspaper     3 non-null      object        \n",
            "dtypes: datetime64[ns](1), object(5)\n",
            "memory usage: 272.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articles_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "le6Mv0K8bkXi",
        "outputId": "5da40a0b-160a-4964-e70e-470f0122fead"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title            authors  \\\n",
              "0  Elbtower Hamburg: Drei Kaufinteressenten sind ...   [Ulrich Gaßdorf]   \n",
              "1   Israels Armee sucht den Goldschatz der Hisbollah    [Bernd Dörries]   \n",
              "2  Grüne verbieten Hunde? Wie CSU zu diesem „Schw...  [Daniel Weidmann]   \n",
              "\n",
              "         date_publish                                           maintext  \\\n",
              "0 2024-10-28 13:25:00  Hamburg. Zu den möglichen Investoren soll eine...   \n",
              "1 2024-10-22 14:56:01  Der Direktor des Krankenhauses, ein Parlaments...   \n",
              "2 2024-10-24 11:18:36  Berlin. Der CSU-Generalsekretär behauptet, die...   \n",
              "\n",
              "                                                 url        newspaper  \n",
              "0  https://www.abendblatt.de/hamburg/hamburg-mitt...    abendblatt.de  \n",
              "1  https://www.sueddeutsche.de/politik/israel-his...  sueddeutsche.de  \n",
              "2  https://www.morgenpost.de/politik/article40753...    morgenpost.de  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7636b196-ce58-436b-9668-027cbf371e67\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>authors</th>\n",
              "      <th>date_publish</th>\n",
              "      <th>maintext</th>\n",
              "      <th>url</th>\n",
              "      <th>newspaper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Elbtower Hamburg: Drei Kaufinteressenten sind ...</td>\n",
              "      <td>[Ulrich Gaßdorf]</td>\n",
              "      <td>2024-10-28 13:25:00</td>\n",
              "      <td>Hamburg. Zu den möglichen Investoren soll eine...</td>\n",
              "      <td>https://www.abendblatt.de/hamburg/hamburg-mitt...</td>\n",
              "      <td>abendblatt.de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Israels Armee sucht den Goldschatz der Hisbollah</td>\n",
              "      <td>[Bernd Dörries]</td>\n",
              "      <td>2024-10-22 14:56:01</td>\n",
              "      <td>Der Direktor des Krankenhauses, ein Parlaments...</td>\n",
              "      <td>https://www.sueddeutsche.de/politik/israel-his...</td>\n",
              "      <td>sueddeutsche.de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Grüne verbieten Hunde? Wie CSU zu diesem „Schw...</td>\n",
              "      <td>[Daniel Weidmann]</td>\n",
              "      <td>2024-10-24 11:18:36</td>\n",
              "      <td>Berlin. Der CSU-Generalsekretär behauptet, die...</td>\n",
              "      <td>https://www.morgenpost.de/politik/article40753...</td>\n",
              "      <td>morgenpost.de</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7636b196-ce58-436b-9668-027cbf371e67')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7636b196-ce58-436b-9668-027cbf371e67 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7636b196-ce58-436b-9668-027cbf371e67');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d9f8f818-f0db-4df8-b981-5065cc8ab842\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9f8f818-f0db-4df8-b981-5065cc8ab842')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d9f8f818-f0db-4df8-b981-5065cc8ab842 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "articles_df",
              "summary": "{\n  \"name\": \"articles_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Elbtower Hamburg: Drei Kaufinteressenten sind noch im Rennen\",\n          \"Israels Armee sucht den Goldschatz der Hisbollah\",\n          \"Gr\\u00fcne verbieten Hunde? Wie CSU zu diesem \\u201eSchwachsinn\\u201c kommt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date_publish\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-10-22 14:56:01\",\n        \"max\": \"2024-10-28 13:25:00\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2024-10-28 13:25:00\",\n          \"2024-10-22 14:56:01\",\n          \"2024-10-24 11:18:36\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"maintext\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Hamburg. Zu den m\\u00f6glichen Investoren soll eine bekannte t\\u00fcrkische Firma geh\\u00f6ren. Doch auch zwei Konsortien aus Hamburg hoffen auf den Zuschlag.\",\n          \"Der Direktor des Krankenhauses, ein Parlamentsabgeordneter der Hisbollah-nahen Amal-Partei, bestritt die Vorw\\u00fcrfe, lie\\u00df das Krankenhaus am Dienstag aber r\\u00e4umen und Journalisten ins Geb\\u00e4ude hinein, gleichzeitig twitterte ein israelischer Armeesprecher Aufforderungen, man solle sich nicht blenden lassen und in den Keller gehen, wo das Geld liege. Gefunden wurde offenbar nichts.\\nDie Hausbank der Terrororganisation soll Gelder aus deren kriminellen Aktivit\\u00e4ten gewaschen haben\\nDie israelische Armee hatte in den vergangenen Tagen immer wieder das Finanzsystem der Hisbollah ins Visier genommen, vor allem die Al-Kard-Al-Hassan-Bank, mindestens 20 ihrer Filialen in Beirut und anderen Landesteilen wurden angegriffen und dabei teilweise ganze Wohngeb\\u00e4ude zerst\\u00f6rt, in deren Erdgeschoss sich die Zweigstellen befanden. Laut israelischer Armee werden durch Al-Kard Al-Hassan der Terror finanziert, Hisbollah-K\\u00e4mpfer bezahlt und Waffenk\\u00e4ufe erm\\u00f6glicht. Bereits bei der T\\u00f6tung von Hassan Nasrallah Ende Oktober sollen gro\\u00dfe Mengen Bargeld durch die Bomben auf den Bunker des Hisbollah-F\\u00fchrers vernichtet worden sein. Al-Kard Al-Hassan wurde in der Vergangenheit von westlichen Geheimdiensten vorgeworfen, Gelder aus dem Drogenhandel und kriminellen Aktivit\\u00e4ten der Hisbollah zu waschen oder ins Land zu transferieren.\\nAl-Kard Al-Hassan bedeutet so etwas wie \\u201eDas gute Darlehen\\u201c, es ist eine Finanzinstitution nach islamischen Regeln, die Zinsen und Wucher verbieten. Die Bank wurde 1983 gegr\\u00fcndet und soll derzeit etwa 300 000 Privatkunden haben, vor allem schiitische Libanesen. Hisbollah-F\\u00fchrer Nasrallah pries die Bank 2021 in einer Rede als gro\\u00dfen Gewinn f\\u00fcr die schiitische Gemeinschaft, seit ihrem Bestehen habe sie 3,7 Milliarden Dollar Kredite an 1,8 Millionen Kunden vergeben.\\nDer Finanzier Iran ist klamm, das hat Folgen f\\u00fcr die Hisbollah\\nBei einem Gro\\u00dfteil d\\u00fcrfte es sich um Kleinkredite gehandelt haben, viele Schiiten bringen Gold oder Familienschmuck zu Al-Kard Al-Hassan und erhalten im Gegenzug ein Darlehen f\\u00fcr Schulgeb\\u00fchren oder Beerdigungen. Die Hisbollah soll vielen Kunden bereits per Whatsapp versichert haben, dass ihre Einlagen noch da sind. Die Bank hatte w\\u00e4hrend der libanesischen Wirtschaftskrise, die 2019 begann und die Ersparnisse vieler Menschen vernichtete, an Reputation gewonnen. W\\u00e4hrend Kunden des offiziellen Sektors nicht mehr an ihre Dollar kamen und die lokale W\\u00e4hrung 97 Prozent ihres Wertes verlor, \\u00e4nderte sich f\\u00fcr die Kunden der Al-Kard-Al-Hassan-Bank nichts, sie kamen weiter an ihr Geld.\\nDie Finanzsituation der Hisbollah insgesamt scheint sich aber in den vergangenen Jahren verschlechtert zu haben, der gro\\u00dfe Finanzier Iran ist in einer schweren Wirtschaftskrise. Vor allem im S\\u00fcden Libanons w\\u00e4chst die Wut auf die Hisbollah, weil sie offenbar nicht das Geld hat, die von Israel zerst\\u00f6rten H\\u00e4user und Einrichtungen wieder aufzubauen. Oder \\u00fcberhaupt nennenswerte humanit\\u00e4re Hilfe f\\u00fcr die mehr als eine Million Menschen zu leisten, die ihre H\\u00e4user verlassen mussten. Das war nach dem Krieg 2006 noch anders, damals soll es f\\u00fcr jedes zerst\\u00f6rte Haus etwa 120 000 Dollar gegeben haben.\\nViele libanesische Hisbollah-Analysten denken, dass die Angriffe auf das Finanzsystem nicht so sehr dazu dienen, die milit\\u00e4rische Kraft der Hisbollah zu schw\\u00e4chen, sondern eher psychologischer Natur sind, um die Anh\\u00e4ngerschaft zu verunsichern.\\nDen angeblichen Goldschatz unter dem Krankenhaus werde man nicht attackieren, hatte der israelische Armeesprecher noch am Montag gesagt, der Krieg richte sich nicht gegen das libanesische Volk. Wenig sp\\u00e4ter traf eine Bombe die Nachbarschaft des Rafik-Hariri-Krankenhauses, 13 Menschen wurden get\\u00f6tet.\",\n          \"Berlin. Der CSU-Generalsekret\\u00e4r behauptet, die Gr\\u00fcne Jugend will Hunde verbieten. Woher das Narrativ kommt \\u2013 und warum Lang auf Trump verweist.\\nAus ihrer Ablehnung gr\\u00fcner Politik, sogar der ganzen Partei, macht die CSU keinen Hehl: Gebetsm\\u00fchlenartig wiederholen f\\u00fchrende K\\u00f6pfe der bayrischen Schwesterpartei ihr Mantra, das sich zwischen \\u201eNein zu Schwarz-Gr\\u00fcn\\u201c und \\u201eGr\\u00fcne sind gegen Bayern\\u201c einpendelt. So zumindest formulierte es CSU-Chef und Ministerpr\\u00e4sident Markus S\\u00f6der bei seiner Parteitagsrede.\\nWas zun\\u00e4chst als eindeutige Koalitionsabsage begann, scheint jetzt zur Wahlkampfstrategie der CSU zu werden, die in \\u00fcberspitzter Form die sozialen Medien erreicht. Dort postete CSU-General Martin Huber ein Video, indem er sich als Besch\\u00fctzer von Haustierbesitzern inszeniert. Seine These: Die Gr\\u00fcne Jugend will Hundebesitzern ihre Haustiere wegnehmen.\\nCSU postet Video: Woher kommt der Vorwurf?\\n\\u201eSie sind f\\u00fcr viele Wegbegleiter, Kummerkasten, Familienmitglied und Spielgef\\u00e4hrte\\u201c, spricht er in die Kamera, w\\u00e4hrend ein Hund vor ihm auf und ab h\\u00fcpft. Hinterlegt wird das Video, das der Generalsekret\\u00e4r unter anderem via Instagram verbreitete, mit Klaviermusik. \\u201eUnd die Gr\\u00fcne Jugend m\\u00f6chte Euch das verbieten und einen treuen Freund wegnehmen. Was f\\u00fcr ein herzloser Irrsinn\\u201c, res\\u00fcmiert Huber.\\nHubers These st\\u00fctzt sich auf einen Beitrag der \\u201eBild\\u201c, den er zu Beginn seines Videos als Screenshot einblendet und den die CSU als Sharepic verbreitet. \\u201eWelpen-Feind ist neuer Junior-Chef der Gr\\u00fcnen\\u201c titelte das Medium, nachdem Jakob Blasel und Jette Nietzard zum neuen F\\u00fchrungsduo der Gr\\u00fcnen Jugend bestimmt wurden.\\nAuch interessant\\nRicarda Lang vergleicht Hubers Aussage mit der von Trump\\nDie \\u201eBild\\u201c leitete diese Behauptung aus einem Interview ab, das Blasel 2019 dem ARD-Jugendformat Funk gegeben hatte. \\u201eSo liebensw\\u00fcrdig unsere Haustiere auch sind, wir brauchen sie eigentlich nicht, und das ist ein ziemlicher Umwelt- und CO\\u2082-Luxus, den wir uns da leisten\\u201c, zitieren verschiedene Medien aus dem Video, das nicht mehr online ist.\\nDer Fridays For Future Mitbegr\\u00fcnder pl\\u00e4dierte demnach daf\\u00fcr, es zu verbieten, die Tiere unn\\u00f6tig zu z\\u00fcchten. Unter anderem der Bayrische Rundfunk zitiert Blasel mit der Empfehlung, \\u201evor allem Tiere aus dem Tierheim zu nehmen, wenn wir denn gern ein Haustier h\\u00e4tten\\u201c. Von einer Forderung nach einem Haustierverbot: keine Spur.\\nIn den sozialen Medien traf Hubers Video bei f\\u00fchrenden K\\u00f6pfen der Gr\\u00fcnen auf wenig Gegenliebe und H\\u00e4me. In einem Video verweist die scheidende Gr\\u00fcnen-Vorsitzende Ricarda Lang auf die Aussage Donald Trumps, der behauptet hatte, dass Haitianer in den USA Katzen und Hunde essen w\\u00fcrden. \\u201eUnd da hat sich die CDU gedacht: Was Donald kann, das k\\u00f6nnen wir schon l\\u00e4nger\\u201c, so Lang via X. \\u201eDas ist nat\\u00fcrlich kompletter Schwachsinn.\\u201c\\nGr\\u00fcnen-Europaabgeordneter Erik Marquardt kommentierte neben Hubers Beitrag: \\u201eDas C in CSU steht auf jeden Fall f\\u00fcr crazy.\\u201c\\nAuch interessant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"https://www.abendblatt.de/hamburg/hamburg-mitte/article407529183/elbtower-kauft-tuerkische-firma-hamburgs-kuenftiges-wahrzeichen.html\",\n          \"https://www.sueddeutsche.de/politik/israel-hisbollah-libanon-bank-gold-geld-krankenhaus-lux.TxxwzAtVsoRuvgqkHfMiuy\",\n          \"https://www.morgenpost.de/politik/article407533911/gruene-verbieten-hunde-wie-csu-zu-diesem-schwachsinn-kommt.html\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"newspaper\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"abendblatt.de\",\n          \"sueddeutsche.de\",\n          \"morgenpost.de\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(articles_df.loc[0, 'maintext'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX258_Voe1fR",
        "outputId": "5964f6d0-36a4-4706-a1cd-92ed79562ce8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hamburg. Zu den möglichen Investoren soll eine bekannte türkische Firma gehören. Doch auch zwei Konsortien aus Hamburg hoffen auf den Zuschlag.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install newspaper_scraper"
      ],
      "metadata": {
        "id": "Kd-sGSyqLgLh",
        "outputId": "075fc794-f38b-4cea-8a3d-78021e544981",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting newspaper_scraper\n",
            "  Downloading newspaper_scraper-0.2.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from newspaper_scraper) (2.2.2)\n",
            "Collecting selenium (from newspaper_scraper)\n",
            "  Downloading selenium-4.26.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from newspaper_scraper) (4.12.3)\n",
            "Collecting goose3==3.1.11 (from newspaper_scraper)\n",
            "  Downloading goose3-3.1.11-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from newspaper_scraper) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from goose3==3.1.11->newspaper_scraper) (2.32.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from goose3==3.1.11->newspaper_scraper) (10.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from goose3==3.1.11->newspaper_scraper) (5.3.0)\n",
            "Requirement already satisfied: cssselect in /usr/local/lib/python3.10/dist-packages (from goose3==3.1.11->newspaper_scraper) (1.2.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from goose3==3.1.11->newspaper_scraper) (0.42.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from goose3==3.1.11->newspaper_scraper) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from goose3==3.1.11->newspaper_scraper) (2.8.2)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from goose3==3.1.11->newspaper_scraper) (1.0.9)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->newspaper_scraper) (2.6)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->newspaper_scraper) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->newspaper_scraper) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->newspaper_scraper) (2024.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium->newspaper_scraper) (2.2.3)\n",
            "Collecting trio~=0.17 (from selenium->newspaper_scraper)\n",
            "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium->newspaper_scraper)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium->newspaper_scraper) (2024.8.30)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium->newspaper_scraper) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium->newspaper_scraper) (1.8.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->goose3==3.1.11->newspaper_scraper) (1.16.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->newspaper_scraper) (24.2.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium->newspaper_scraper)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->newspaper_scraper) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium->newspaper_scraper)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->newspaper_scraper) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->newspaper_scraper) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium->newspaper_scraper)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium->newspaper_scraper) (1.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->goose3==3.1.11->newspaper_scraper) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->goose3==3.1.11->newspaper_scraper) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->goose3==3.1.11->newspaper_scraper) (2024.9.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->goose3==3.1.11->newspaper_scraper) (3.4.0)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->newspaper_scraper) (0.14.0)\n",
            "Downloading newspaper_scraper-0.2.1-py3-none-any.whl (31 kB)\n",
            "Downloading goose3-3.1.11-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.26.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.7/481.7 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: sortedcontainers, wsproto, outcome, trio, goose3, trio-websocket, selenium, newspaper_scraper\n",
            "Successfully installed goose3-3.1.11 newspaper_scraper-0.2.1 outcome-1.3.0.post0 selenium-4.26.1 sortedcontainers-2.4.0 trio-0.27.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import newspaper_scraper as nps"
      ],
      "metadata": {
        "id": "NfOCdT0Ep7k0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#with nps.DeBild(db_files='articles_debild.db') as news: #this does not compile, we should find a way to write files while using colab\n",
        "  #news.index_articles_by_date_range('2023-09-01', '2023-09-30') #fron 1st to 30th september 2023\n",
        "  #news.scrape_public_articles()\n",
        "  #it's also possible to apply spacy's nlp function directly with the scraping library\n",
        "  #news.nlp()"
      ],
      "metadata": {
        "id": "RIjyMLQsimSn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "a34cb55e-bdad-4963-e96a-4c0f74a622bd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "DeBild.__init__() got an unexpected keyword argument 'db_files'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c1aebf7c4dba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mnps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeBild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'articles_debild.db'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnews\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#this does not compile, we should find a way to write files while using colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mnews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_articles_by_date_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2023-09-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2023-09-30'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fron 1st to 30th september 2023\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mnews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscrape_public_articles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m#it's also possible to apply spacy's nlp function directly with the scraping library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#news.nlp()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: DeBild.__init__() got an unexpected keyword argument 'db_files'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "from urllib.parse import urlparse, urljoin\n",
        "\n",
        "# List of news websites to scrape\n",
        "urls_to_scrape = [\n",
        "    \"https://www.spiegel.de\",   # Der Spiegel\n",
        "    \"https://www.zeit.de\",      # Die Zeit\n",
        "    \"https://www.sueddeutsche.de\"  # Süddeutsche Zeitung\n",
        "]\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"\n",
        "}\n",
        "\n",
        "article_urls = set()  # Use a set to avoid duplicates\n",
        "\n",
        "# Patterns that likely indicate article URLs\n",
        "article_patterns = [\"/artikel/\", \"/news/\", \"/politik/\", \"/wirtschaft/\", \"/sport/\", \"/202\", \"/2023\", \"/2024\"]\n",
        "\n",
        "# Exclude URLs with these keywords\n",
        "exclude_keywords = [\"contact\", \"about\", \"impressum\", \"privacy\", \"datenschutz\", \"jobs\", \"login\"]\n",
        "\n",
        "for base_url in urls_to_scrape:\n",
        "    try:\n",
        "        response = requests.get(base_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        parsed_base_url = urlparse(base_url).netloc\n",
        "\n",
        "        for link in soup.find_all(\"a\", href=True):\n",
        "            href = link['href']\n",
        "            full_url = urljoin(base_url, href)  # Convert to absolute URL\n",
        "\n",
        "            # Ensure the URL belongs to the base domain and matches article patterns\n",
        "            parsed_url = urlparse(full_url)\n",
        "            if (parsed_url.netloc == parsed_base_url and\n",
        "                any(pattern in full_url for pattern in article_patterns) and\n",
        "                not any(keyword in full_url for keyword in exclude_keywords)):\n",
        "                article_urls.add(full_url)\n",
        "\n",
        "        # Stop when we have 1000 unique URLs\n",
        "        if len(article_urls) >= 1000:\n",
        "            break\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching {base_url}: {e}\")\n",
        "\n",
        "# Save URLs to a CSV file\n",
        "with open(\"filtered_news_article_urls.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    for article_url in list(article_urls)[:1000]:  # Limit to 1000 URLs\n",
        "        writer.writerow([article_url])\n",
        "\n",
        "print(\"Filtered article URLs saved to filtered_news_article_urls.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkCNt5Q8wTSg",
        "outputId": "c8a49e48-1943-4550-a4a3-dc5465110707"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered article URLs saved to filtered_news_article_urls.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urls_file = pd.read_csv(\"news_article_urls.csv\")"
      ],
      "metadata": {
        "id": "tgZRRif7xbMn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls_file.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "24nUs8qSxk9_",
        "outputId": "f9e4ff5b-cc49-4537-c5a6-d53e8d4e4bad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  https://boersen.manager-magazin.de/kursinformation/DE0008469008/\n",
              "0           https://gutscheine.spiegel.de/alle-shops              \n",
              "1  https://sz-magazin.sueddeutsche.de/gesundheit/...              \n",
              "2                 https://shop.zeit.de/geschenke-zon              \n",
              "3  https://streaming-guide.spiegel.de/streamingdi...              \n",
              "4  https://stellenmarkt.sueddeutsche.de/jobs/medi...              \n",
              "5                 https://seniorenportal.spiegel.de/              \n",
              "6  https://spiele.spiegel.de/snake/?utm_campaign=...              \n",
              "7  https://quiz.sueddeutsche.de/quiz/50ceff3b49fd...              \n",
              "8                             https://twitter.com/sz              \n",
              "9    https://gruppenkonto.spiegel.de/kuendigung.html              "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13c0da16-71c4-4896-b604-77768684b800\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>https://boersen.manager-magazin.de/kursinformation/DE0008469008/</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://gutscheine.spiegel.de/alle-shops</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://sz-magazin.sueddeutsche.de/gesundheit/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://shop.zeit.de/geschenke-zon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://streaming-guide.spiegel.de/streamingdi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://stellenmarkt.sueddeutsche.de/jobs/medi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>https://seniorenportal.spiegel.de/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>https://spiele.spiegel.de/snake/?utm_campaign=...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>https://quiz.sueddeutsche.de/quiz/50ceff3b49fd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>https://twitter.com/sz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>https://gruppenkonto.spiegel.de/kuendigung.html</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13c0da16-71c4-4896-b604-77768684b800')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13c0da16-71c4-4896-b604-77768684b800 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13c0da16-71c4-4896-b604-77768684b800');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c7508214-00b2-4f42-a38c-9a82beda90dc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7508214-00b2-4f42-a38c-9a82beda90dc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c7508214-00b2-4f42-a38c-9a82beda90dc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "urls_file",
              "summary": "{\n  \"name\": \"urls_file\",\n  \"rows\": 223,\n  \"fields\": [\n    {\n      \"column\": \"https://boersen.manager-magazin.de/kursinformation/DE0008469008/\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 223,\n        \"samples\": [\n          \"https://gruppenkonto.spiegel.de/kuendigung.html\",\n          \"https://premium.zeit.de/abo/diezeit?wt_zmc=fix.int.zonpme.zeitde.epaper.z+.home.bildtext.bildtext&utm_medium=fix&utm_source=zeitde_zonpme_int&utm_campaign=epaper&utm_content=z+_home_bildtext_bildtext\",\n          \"https://zeit.de#\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urls_file.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_rUzSN7xmR3",
        "outputId": "18d562d4-3ac6-4729-859e-7d1112f8a551"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 223 entries, 0 to 222\n",
            "Data columns (total 1 columns):\n",
            " #   Column                                                            Non-Null Count  Dtype \n",
            "---  ------                                                            --------------  ----- \n",
            " 0   https://boersen.manager-magazin.de/kursinformation/DE0008469008/  223 non-null    object\n",
            "dtypes: object(1)\n",
            "memory usage: 1.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X-WuEN48zxcb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}